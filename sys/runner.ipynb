{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/miniconda3/envs/si650/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import gzip\n",
    "from datetime import datetime\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import re\n",
    "import joblib\n",
    "\n",
    "# your modules are imported here\n",
    "from indexing import Indexer, BasicInvertedIndex\n",
    "from document_preprocessor import RegexTokenizer, Doc2QueryAugmenter\n",
    "from ranker import Ranker, BM25, CrossEncoderScorer\n",
    "from vector_ranker import VectorRanker\n",
    "from l2r import L2RFeatureExtractor, L2RRanker\n",
    "from vectordb_ranker import VectorDBRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import indexing\n",
    "reload(indexing)\n",
    "from indexing import Indexer\n",
    "import document_preprocessor\n",
    "reload(document_preprocessor)\n",
    "from document_preprocessor import RegexTokenizer, Doc2QueryAugmenter\n",
    "import l2r\n",
    "reload(l2r)\n",
    "from l2r import L2RFeatureExtractor, L2RRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prefix = '../data/'\n",
    "model_prefix = '../models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_prefix + 'rec_cats.json', 'r') as f:\n",
    "    rec_cats = json.load(f)\n",
    "    five_cats = rec_cats['short']\n",
    "    all_cats = rec_cats['full']\n",
    "with open(data_prefix + 'doc_cat_info.json', 'r') as f:\n",
    "    doc_cat_info = json.load(f)\n",
    "    doc_cat_info = {int(k):v for k, v in doc_cat_info.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../interior_dic.json', 'r') as f:\n",
    "#     query_alts_rels = json.load(f)\n",
    "#     queries = list(query_alts_rels.keys())\n",
    "#     for query in queries:\n",
    "#         del query_alts_rels[query]['alt_qs'][5]\n",
    "#         for i in range(5):\n",
    "#             q = query_alts_rels[query]['alt_qs'][i]\n",
    "#             query_alts_rels[query]['alt_qs'][i] = q[3:]\n",
    "#         query_alts_rels[query]['scored_docs'] = [(l[0], l[1]) for l in query_alts_rels[query]['scored_docs']]\n",
    "#     train_queries = queries[:41]\n",
    "#     test_queries = queries[41:]\n",
    "# with open('../train_data.json', 'w') as f:\n",
    "#     train_data = {query: query_alts_rels[query] for query in train_queries}\n",
    "#     test_data = {query: query_alts_rels[query] for query in test_queries}\n",
    "#     json.dump(train_data, f, indent=2)\n",
    "# with open('../test_data.json', 'w') as f:\n",
    "#     json.dump(test_data, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug1 = Doc2QueryAugmenter()\n",
    "# aug2 = Doc2QueryAugmenter('doc2query/msmarco-t5-small-v1')\n",
    "# aug3 = Doc2QueryAugmenter('google/flan-t5-small')\n",
    "# prefix = \"Generate a query for the following text: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../final_data_with_categories.json', 'r') as f:\n",
    "#     lines = f.readlines()\n",
    "#     docs = []\n",
    "#     for line in tqdm(lines):\n",
    "#         doc = json.loads(line)\n",
    "#         doc['alt_qs'] = aug1.get_queries(doc['text'], 5)\n",
    "#         doc['dumb_qs_1'] = aug2.get_queries(doc['text'], 5)\n",
    "#         doc['dumb_qs_2'] = aug3.get_queries(doc['text'], 5, prefix)\n",
    "#         docs.append(doc)\n",
    "# with open('../data/doc_dataset.jsonl', 'a') as f:\n",
    "#     for doc in docs:\n",
    "#         f.write(json.dumps(doc) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/doc_dataset_old.jsonl', 'r') as f:\n",
    "#     line = f.readline()\n",
    "#     doc_inds = [m.start() for m in re.finditer('{\"docid\":', line)]\n",
    "#     docs = []\n",
    "#     for i in range(len(doc_inds)):\n",
    "#         start = doc_inds[i]\n",
    "#         end = len(line) if i == len(doc_inds) - 1 else doc_inds[i + 1]\n",
    "#         doc_text = line[start:end]\n",
    "#         doc = json.loads(doc_text)\n",
    "#         docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/doc_dataset.jsonl', 'a') as f:\n",
    "#     for doc in docs:\n",
    "#         f.write(json.dumps(doc) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stopwords collected 543'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_preproc = RegexTokenizer('\\\\w+')\n",
    "stopwords = set()\n",
    "with open(data_prefix + 'stopwords.txt', 'r', encoding='utf-8') as file:\n",
    "    for stopword in file:\n",
    "        stopwords.add(stopword.strip())\n",
    "f'Stopwords collected {len(stopwords)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_base_index = Indexer.create_index(data_prefix + 'doc_dataset.jsonl', doc_preproc, stopwords, 'text', 'alt_qs', data_prefix + 'doc_base_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_base_index = BasicInvertedIndex()\n",
    "doc_base_index.load(data_prefix + 'doc_base_index')\n",
    "doc_small_index = BasicInvertedIndex()\n",
    "doc_small_index.load(data_prefix + 'doc_small_index')\n",
    "doc_flan_index = BasicInvertedIndex()\n",
    "doc_flan_index.load(data_prefix + 'doc_flan_index')\n",
    "doc_index = BasicInvertedIndex()\n",
    "doc_index.load(data_prefix + 'doc_index')\n",
    "tit_index = BasicInvertedIndex()\n",
    "tit_index.load(data_prefix + 'title_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_small_index = Indexer.create_index(data_prefix + 'doc_dataset.jsonl', doc_preproc, stopwords, 'text', 'dumb_qs_1', data_prefix + 'doc_small_index')\n",
    "# doc_flan_index = Indexer.create_index(data_prefix + 'doc_dataset.jsonl', doc_preproc, stopwords, 'text', 'dumb_qs_2', data_prefix + 'doc_flan_index')\n",
    "# doc_index = Indexer.create_index(data_prefix + 'doc_dataset.jsonl', doc_preproc, stopwords, 'text', '', data_prefix + 'doc_index')\n",
    "# tit_index = Indexer.create_index(data_prefix + 'doc_dataset.jsonl', doc_preproc, stopwords, 'title', '', data_prefix + 'title_index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_runner(ranker, queries):\n",
    "    scores = [ranker.query(query) for query in queries]\n",
    "    final_scores = []\n",
    "    docids = [dic['docid'] for dic in scores[0]]\n",
    "    for doc in docids:\n",
    "        cum_score = 0\n",
    "        for score_l in scores:\n",
    "            for dic in score_l:\n",
    "                if dic['docid'] == doc:\n",
    "                    cum_score += dic['score']\n",
    "                    break\n",
    "        final_scores.append({'docid': doc, 'score': cum_score / len(queries)})\n",
    "    return final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_prefix + 'raw_text.json', 'r') as f:\n",
    "    raw_text_dict = json.load(f)\n",
    "    raw_text_dict = {int(k):v for k, v in raw_text_dict.items()}\n",
    "with open(data_prefix + 'base_raw_text.json', 'r') as f:\n",
    "    base_raw_text_dict = json.load(f)\n",
    "    base_raw_text_dict = {int(k):v for k, v in base_raw_text_dict.items()}\n",
    "with open(data_prefix + 'small_raw_text.json', 'r') as f:\n",
    "    small_raw_text_dict = json.load(f)\n",
    "    small_raw_text_dict = {int(k):v for k, v in small_raw_text_dict.items()}\n",
    "with open(data_prefix + 'flan_raw_text.json', 'r') as f:\n",
    "    flan_raw_text_dict = json.load(f)\n",
    "    flan_raw_text_dict = {int(k):v for k, v in flan_raw_text_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_scorer = CrossEncoderScorer(raw_text_dict)\n",
    "bce_scorer = CrossEncoderScorer(base_raw_text_dict)\n",
    "sce_scorer = CrossEncoderScorer(small_raw_text_dict)\n",
    "fce_scorer = CrossEncoderScorer(flan_raw_text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_feat_extract = L2RFeatureExtractor(doc_index, tit_index, doc_cat_info, doc_preproc, stopword, set(), ce_scorer)\n",
    "nf_feat_extract = L2RFeatureExtractor(doc_index, tit_index, doc_cat_info, doc_preproc, stopword, set(five_cats), ce_scorer)\n",
    "na_feat_extract = L2RFeatureExtractor(doc_index, tit_index, doc_cat_info, doc_preproc, stopword, set(all_cats), ce_scorer)\n",
    "bf_feat_extract = L2RFeatureExtractor(doc_base_index, tit_index, doc_cat_info, doc_preproc, stopword, set(five_cats), bce_scorer)\n",
    "sf_feat_extract = L2RFeatureExtractor(doc_small_index, tit_index, doc_cat_info, doc_preproc, stopword, set(five_cats), sce_scorer)\n",
    "ff_feat_extract = L2RFeatureExtractor(doc_flan_index, tit_index, doc_cat_info, doc_preproc, stopword, set(five_cats), fce_scorer)\n",
    "ba_feat_extract = L2RFeatureExtractor(doc_base_index, tit_index, doc_cat_info, doc_preproc, stopword, set(all_cats), bce_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "nn_model = joblib.load(model_prefix + 'nn_model.joblib')\n",
    "nf_model = joblib.load(model_prefix + 'nf_model.joblib')\n",
    "na_model = joblib.load(model_prefix + 'na_model.joblib')\n",
    "bf_model = joblib.load(model_prefix + 'bf_model.joblib')\n",
    "sf_model = joblib.load(model_prefix + 'sf_model.joblib')\n",
    "ff_model = joblib.load(model_prefix + 'ff_model.joblib')\n",
    "ba_model = joblib.load(model_prefix + 'ba_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_prefix + 'test_data.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "    test_queries = list(test_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_ranker = BM25(doc_index)\n",
    "vdb_ranker = VectorDBRanker(raw_text_dict)\n",
    "bvdb_ranker = VectorDBRanker(base_raw_text_dict)\n",
    "svdb_ranker = VectorDBRanker(small_raw_text_dict)\n",
    "fvdb_ranker = VectorDBRanker(flan_raw_text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_nq_nn_ranker = L2RRanker(doc_index, tit_index, doc_preproc, stopword, bm25_ranker, nn_feat_extract)\n",
    "bm25_nq_nn_ranker.model.lgbmranker = nn_model\n",
    "bm25_nq_nn_scores = [bm25_nq_nn_ranker.query(query) for query in test_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_nq_nf_ranker = L2RRanker(doc_index, tit_index, doc_preproc, stopword, bm25_ranker, nf_feat_extract)\n",
    "bm25_nq_nf_ranker.model.lgbmranker = nf_model\n",
    "bm25_nq_nf_scores = [bm25_nq_nf_ranker.query(query) for query in test_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bienc_nq_nn_ranker = L2RRanker(doc_index, tit_index, doc_preproc, stopword, vdb_ranker, nn_feat_extract)\n",
    "bienc_nq_nn_ranker.model.lgbmranker = nn_model\n",
    "bienc_nq_nn_scores = [bm25_nq_nn_ranker.query(query) for query in test_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bienc_nq_na_ranker = L2RRanker(doc_index, tit_index, doc_preproc, stopword, vdb_ranker, na_feat_extract)\n",
    "bienc_nq_na_ranker.model.lgbmranker = na_model\n",
    "bienc_nq_na_scores = [bienc_nq_na_ranker.query(query) for query in test_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bienc_nq_nf_ranker = L2RRanker(doc_index, tit_index, doc_preproc, stopword, vdb_ranker, nf_feat_extract)\n",
    "bienc_nq_nf_ranker.model.lgbmranker = nf_model\n",
    "bienc_nq_nf_scores = [bienc_nq_nf_ranker.query(query) for query in test_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bienc_tq_nf_ranker = L2RRanker(doc_index, tit_index, doc_preproc, stopword, vdb_ranker, nf_feat_extract)\n",
    "bienc_tq_nf_ranker.model.lgbmranker = nf_model\n",
    "bienc_tq_nf_scores = [query_runner(bienc_tq_nf_ranker, [query, test_data[query]['alt_qs'][-1]]) for query in test_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bienc_sq_nf_ranker = L2RRanker(doc_index, tit_index, doc_preproc, stopword, vdb_ranker, nf_feat_extract)\n",
    "bienc_sq_nf_ranker.model.lgbmranker = nf_model\n",
    "bienc_sq_nf_scores = [query_runner(bienc_sq_nf_ranker, [query] + test_data[query]['alt_qs'][:5]) for query in test_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bienc_aq_nf_ranker = L2RRanker(doc_index, tit_index, doc_preproc, stopword, vdb_ranker, nf_feat_extract)\n",
    "bienc_aq_nf_ranker.model.lgbmranker = nf_model\n",
    "bienc_aq_nf_scores = [query_runner(bienc_aq_nf_ranker, [query] + test_data[query]['alt_qs']) for query in test_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bienc_nq_bf_ranker = L2RRanker(doc_base_index, tit_index, doc_preproc, stopword, bvdb_ranker, bf_feat_extract)\n",
    "bienc_nq_bf_ranker.model.lgbmranker = bf_model\n",
    "bienc_nq_bf_scores = [bienc_nq_bf_ranker.query(query) for query in test_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bienc_nq_sf_ranker = L2RRanker(doc_small_index, tit_index, doc_preproc, stopword, svdb_ranker, sf_feat_extract)\n",
    "bienc_nq_sf_ranker.model.lgbmranker = sf_model\n",
    "bienc_nq_sf_scores = [bienc_nq_sf_ranker.query(query) for query in test_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bienc_nq_ff_ranker = L2RRanker(doc_flan_index, tit_index, doc_preproc, stopword, fvdb_ranker, ff_feat_extract)\n",
    "bienc_nq_ff_ranker.model.lgbmranker = ff_model\n",
    "bienc_nq_ff_scores = [bienc_nq_ff_ranker.query(query) for query in test_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bienc_aq_ba_ranker = L2RRanker(doc_base_index, tit_index, doc_preproc, stopword, bvdb_ranker, ba_feat_extract)\n",
    "bienc_aq_ba_ranker.model.lgbmranker = ba_model\n",
    "bienc_aq_ba_scores = [query_runner(bienc_aq_ba_ranker, [query] + test_data[query]['alt_qs']) for query in test_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "true_relevance = np.array([[20, 0, 0, 1, 5]])\n",
    "scores = np.array([[-10, -100, -100, -15, -12]])\n",
    "ndcg_score(true_relevance, scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si650",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
